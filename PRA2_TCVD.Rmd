---
title: "Tipología y ciclo de vide de los datos: Pr2 - Como realizar la limpieza y análisis de datos"
author: "Alejandro Hernández Slamerón, Almir Cáceres Barraquero"
date: "Junio 2023"
output: 
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Descripción del dataset 



# Integración y seleccion

Ahora vamos a ver los datos de que se dispone para realizar un primer estudio sobre las posibles decisiones previas que se han de tomar. 
Para ello cargamos el dataset y revisamos todos las variables que disponemos, para verificar cual podemos utilizar en estudios posteriores.

```{r message= FALSE, warning=FALSE}
# IMPORTACIÓN DE LIBRERÍAS

if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
if (!require('Hmisc')) install.packages('Hmisc'); library('Hmisc')
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')
if(!require("corrplot")) install.packages("corrplot"); library("corrplot")
```

```{r}
path = 'heart.CSV'
df_heart <- read.csv(path, row.names=NULL)
```

```{r}
head(df_heart)
```



Vemos que disponemos de las siguientes variables para el estudio:


+ **age** Age of the patient in years
+ **sex** Sex of the patient
+ **cp** chest pain type:
(1= typical angina, 
2= atypical angina, 
3= non-anginal, 
4= asymptomatic)
+ **trtbps** resting blood pressure (in mm Hg)
+ **chol**  cholestoral in mg/dl fetched via BMI sensor
+ **fbs** fasting blood sugar > 120 mg/dl (1 = true; 0 = false)
+ **restecg** resting electrocardiographic results 
Value 0: normal,
Value 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV),
Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria
+ **thalachh**	 maximum heart rate achieved
+ **exan**	exang: exercise induced angina (1 = yes; 0 = no)
+ **oldpeak** ST depression induced by exercise relative to rest	
+ **slp** the slope of the peak exercise ST segment
+ **caa** 	number of major vessels (0-3) colored by fluoroscopy
+ **thall** 	3normal; fixed defect; reversible defect
+ **output** the predicted attribute  (0 = less chance of heart attack, 1= more chance of heart attack)

Ahora se va a revisar que tipo de variable es cada una. 

```{r}
structure = str(df_heart)
```

Con esto tenemos la información acerca de la cantidad de datos de los que disponemos y su estructura. 
Como se puede observar, existen 14 variables y un total de 303 datos de estas variables.
Además podemos concluir que todas las variables menos **oldpeak** son variables integrales, lo que nos es muy util para la toma de decisión del tipo de estudio a realizar. 


# Limpieza de datos

Para poder iniciar el análisis de los datos, lo primero es revisar y arreglar los datos donde puedan faltar algún tipo de valores o estos sean erroneos (o puedan dar lugar a resultados erroneo)

## Gestion de elementos erroneos

En primer lugar buscamos todos los datos que tengan alguna variable nulla o vacía. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
print('Blancos')
colSums(df_heart=="")
print('NA')
colSums(is.na(df_heart))
```


Ahora vamos a reviasar los valores de las variables para comprobar si alguna de ellos tuviese valores erroneos. 


```{r}
summary(df_heart)

```



+ **caa**: Esta variable nos dicen en la descripción del dataset que toma valores entre el 0 y el 3. Viendo que su valor máximo es 4, deberíamos eliminar los datos que tengan un valor 4 en esta variable y considerarlos erroneos. 


Eliminamos los valores de caa referentes a 4


```{r message= FALSE, warning=FALSE}

df_heart <- df_heart[!df_heart$caa == 4, ]

```

## Identificación y gestión de valores exremos

Hacemos una última confirmación con el comando describe, para comprobar si hemos de revisar alguna variable más que pueda tener valores anómalos

```{r}
describe(df_heart)
```


+ **oldpeack**: El valor máximo de esta variable es mucho más alto que la media. Esto no quiere deceir que sera erroneo, pero es necesario revisar si estos valores altos son correctos. 

+ **chol**: Al igual que el anterior, el valor máximo de esta variable es mucho más alto que la media. Volvemos a hacer la misma suposición que para la variable anterior, ya que aunque sabemos que estos valores pueden ser altos en ciertas personas, no conocemos exáctamente si estos valores son correctos y pueden afectar al los resultados del estudio. 


Revisamos gráficamente la variable **oldpeak** para ver si tiene valores extremos.


```{r}
boxplot(df_heart$oldpeak, horizontal = TRUE, outline=TRUE)
```


Podemos ver que exsisten 4 valores atípicos que tienen valores más altos de lo normal. Aunque desconocemos si teoricamente estos valores son o no correctos, podemos asumir que son valores anómalos y extraerlos del cálculo final, ya que no va a afectar considerablemente al resultado final. 

```{r message= FALSE, warning=FALSE}
df_heart <- df_heart[!df_heart$oldpeak >= 4, ]

```

Gráficamos también la variable **chol**

```{r}
boxplot(df_heart$chol, horizontal = TRUE, outline=TRUE)
```


Al igual que con la variable **oldpeak**, estos valores no están significativamente separados. Aun así, se van a eliminar los valores anómalos. 

```{r message= FALSE, warning=FALSE}
df_heart <- df_heart[!df_heart$chol >= 400, ]

```
# Análisis de los datos

## Selección de los datos

Una vez hecha la limpieza de datos, se pasa al proceso de análisis.
En primer lugar se ha de definir cual es la finalidad que se busca a la hora del análisis. Para este caso, existe un valor de **output**, el cual toma valores de 0 y 1 y define menor o mayor probabilidad de tener enfermedades cardíacas respectivamente. 

Para decidir el resto de variables que vamos a estudiar, vamos a revisar la distribución de las variables y la correlación que tienen entre ellas. Por ello y en lo referente a este estudio, se van a utilizar las variables cuantitativas, evitando escoger las variables con valores categóricos, las cuales se van a apartar para posibles estudios futuros más efectivos para este tipo de variables como los arboles de decisiones.


Por ello, las variables que se van a estudiar son las siguientes:

+ **age** Podemos intuir que esta variable puede estar muy relacionada con las enfermedades cardíacas, ya que edades avanzadas se relacionan con aumentos de casos de este tipo
+ **trtbps** La presión sanginea tambien es una variable a tener en cuenta, puesto que altas presiones pueden derivar de/o problemas cardíacos. 
+ **chol**  El colesterol es un factor también a tener en cuenta puesto que es un medidor muy utilizado para validar la salud de un paciente. 
+ **thalachh**	No tenemos mucha información sobre esta variable, aún así podemos verificar si puede o no estar relacionada con este tipo de enfermedades.
+ **oldpeak** Esta variable también la vamos a tener en cuenta puesto que sería un punto muy favorable tener un indicador directo de la medida de ritmo cardíaco para poder interpretar este tipo de dolencias cardíacas.
+ **outpu** Este es el valor predicho que indica si existe riesgo o no sobre las dolencias cardíacas. 


## Comprobación de la normalidad y homogeneidad de la varianza


Ahroa se va a comprobar la distribución de las variables, graficando estas para visualizar si siguen o no una distribución normal.


```{r echo=TRUE, message=FALSE, warning=FALSE, fig.width=10, fig.height=20}

histList<- list()

n = c("age","trtbps","chol","thalachh", "oldpeak")
df_heart_plot = df_heart %>% select(all_of(n))
for(y in 1:ncol(df_heart_plot)){
  col <- names(df_heart_plot)[y]
  ggp <- ggplot(df_heart_plot, aes_string(x = col)) +
  geom_histogram(bins = 30, fill = "cornflowerblue", color = "black",ggtittle = "Contador de ocurrencias por variable")
  histList[[y]] <- ggp # añadimos cada plot a la lista vacía
}
multiplot(plotlist = histList, coles = 1)

```


Viendo las gráficas podemos observar que la variable **oldpeak** no sigue una distribución normal. Para el resto necesitaríamos utilizar distintas herramientas para confirmar la asunción o no de normalidad de los datos.

También es posible aplicar pruebas de normalidad a las variables como la Shapiro-Wilk. 

+ **age**
```{r}

normalidad_age = shapiro.test(df_heart$age)
normalidad_age
```

Un alto valor de estadistico W y un valor de p-value > 0,05 nos confirmarían que la distribución de esta variable es normal. En este caso no podemos afirmarlo, ya que aunque el estadístico W es alto, el valor de p-value es menor que el nivel de significancia, por lo que se rechaza la hipótesis nula de normalidad. 

Esto no significa que no sea una distibución normal, ya que la prueba no es necesariamente concluyente. 


+ **trtbps**

```{r}

normalidad_trtbps = shapiro.test(df_heart$trtbps)
normalidad_trtbps
```

Al igual que la variable anterior, no podemos afirmar que siga una distribución normal en base a la prueba. 

+ **chol**

```{r}

normalidad_chol = shapiro.test(df_heart$chol)
normalidad_chol
```

En este caso tanto el estadístico W como el valor p-value están dentro del nivel de significancia para poder confirmar que se trata de una variable con distribución normal. 

+ **thalachh**

```{r}

normalidad_thalachh = shapiro.test(df_heart$thalachh)
normalidad_thalachh
```

En este caso, no se cumple el nivel de significancia del p-value, por lo que se desmiente la hipótesis de distribución normal. 

+ **oldpeak**

```{r}

normalidad_oldpeak = shapiro.test(df_heart$oldpeak)
normalidad_oldpeak
```

Como ya habíamos supuesto al ver la representación gráfica, esta variable no sigue una distribución normal. 

Ahora vamos a ver la correlación que tienen estos datos entre si. Una alta correlación entre variables para crear un modelo indicará que podemos eliminar una de ellas del estudio, ya que esto ayuda a simplificar el problema y evita el overfeeting. Sin embargo, para realizar un estudio estadístico, una alta correlación puede ayudar a la precisión del estudio. 


```{r echo=TRUE, message=FALSE, warning=FALSE}

n = c("age","trtbps","chol","thalachh", "oldpeak", "output")
factores= df_heart %>% select(all_of(n))
res<-cor(factores)
corrplot(res,method="color",tl.col="black", tl.srt=30, order = "AOE",
number.cex=0.75,sig.level = 0.01, addCoef.col = "black")
```


Vemos que ninguna de las variables esta altamente correlacionada, por lo que no podemos eliminar ninguna de estas variables para el estudio por medio de este criterio.

Aqui vemos que, para nuestra variable de predicción **output**, la variable con una mayor correlación es la variable **thalachh** seguida por la variable **age**, que si bien tiene una correlación negativa, es bastante significativa en términos absolutos.


## Aplicación de pruebas estadísticas

### Contraste de hipótesis

Ahora se van a aplicar purebas estadísticas de contraste de hipótesis para la predicción de la probabilidad de tener una enfermedad cardíaca, en función del máximo valor de pulso cardíaco. Esto se va a realacionar con la edad.
Las hipótesis son las siguientes:


+ **Hipótesis nula:**  Un valor alto  de  **thalachh** significa valor alto de edad. 
+ **Hipótesis alternativa:** Valor de **thalachh** no afecta al valor de la edad.




```{r}

# Normalización
min_max_norm <- function(x) {
  (x - min(x)) / (max(x) - min(x))
}


# Aplicar la normalización 
thalachh_norm <- min_max_norm(df_heart$thalachh)
age_norm <- min_max_norm(df_heart$age)

```


```{r}

mean_thalachh <- mean(thalachh_norm)
sd_thalachh <- sd(thalachh_norm)

mean_age <- mean(age_norm)
sd_age <- sd(age_norm)

```

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(kableExtra)

tabla <- matrix(c("", "mean", "sd", "thalachh", mean_thalachh, sd_thalachh, "age", mean_age, sd_age  ), nrow = 3, ncol = 3) # He cambiado "output" por "age" como título de la segunda columna de la tabla.

kable(tabla, digits=2, caption="Media y desviación estandard") %>%
  kable_styling( latex_options=c("striped", "repeat_"),full_width = FALSE)

```




```{r}

#Nivel de confianza

alpha <- 1-0.98
n_thalachh <- length(df_heart$thalachh)
n_output <- length(df_heart$output) # ALMIR: ¿ESTO NO SIRVE PARA NADA NO?

SE <- sd_thalachh / sqrt(n_thalachh)
zobs <- (mean_age - mean_thalachh)/SE
zobs


```


```{r}

zcrit_L <- qnorm(alpha/2)
zcrit_U <- qnorm(1-alpha/2)
c(zcrit_L,zcrit_U)

```

```{r}

pvalue <- pnorm(abs(zobs), lower.tail = FALSE)*2
pvalue

```


El valor de p-value para esta hipótesis es menor que el valor de significancia 0.05, por lo que en este caso se rechaza la hipótesis nula. Esto nos indica que, un alto valor en la edad no significa un alto valor de máximo ritmo cardíaco, cosa que esta dentro de lo que se podría estipular.


Podemos usar también una regresión lineal para modelar la relación entre la variable dependiente (**output**) y las variables independientes. En este caso vamos a normalzar los datos para poder aplicar correctamente el modelo lm. 

```{r}



# Aplicar la normalización para tods las variables a estudiar para poder aplicar el modelo lm
df_heart$age <- min_max_norm(df_heart$age)
df_heart$trtbps <- min_max_norm(df_heart$trtbps)
df_heart$chol <- min_max_norm(df_heart$chol)
df_heart$thalachh <- min_max_norm(df_heart$thalachh)
df_heart$oldpeak <- min_max_norm(df_heart$oldpeak)
```


Ahora se generan dos conjuntos, uno de test y otro de entrenamiento.

```{r, echo=TRUE, eval=TRUE}

# Establecer una semilla para reproducir el valor aleatorio continuamente para poder verificar el modelo creado
set.seed(200)


# Definimos el tamaño de las muestras del juego de datos para el entrenamiento en el 80%
train_size <- round(0.8 * nrow(df_heart))

# Crear índices para el conjunto de entrenamiento y prueba
train_index <- sample(1:nrow(df_heart), train_size, replace = FALSE)
train_df <- df_heart[train_index, ]
test_df <- df_heart[-train_index, ]
dim(train_df)
dim(test_df)
```

```{r}

lr_model1 <- lm( output ~ age + trtbps + chol + thalachh + oldpeak, data = train_df)

# Obtener el resumen del modelo
summary(lr_model)

```


Como vemos en el modelo lm, no se ajusta nada al valor que se requiere, ya que hay variables que tiene un p-value > 0,05. Eliminando estas variables podremos ajustar mejor el valor del modelo. 


```{r}

lr_model2 <- lm( output ~ thalachh + oldpeak, data = train_df)

# Obtener el resumen del modelo
summary(lr_model)

```

Si bien no en gran medida, el ajuste ha bajado un poco. Las variables no tenían mucho peso sin embargo si que aportaban positivamente. Vamos a evaluar ambos modelos.
```{r}
predictions = predict(lr_model1, test_df)
tab = table(predictions>0.5, test_df$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)

predictions = predict(lr_model2, test_df)
tab = table(predictions>0.5, test_df$output)
tab
sum(diag(tab)) / sum(tab)
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)

cat("")
```
Podemos ver que la eliminación de las variables ha mejorado el resultado, hemos pasado de 15 negativos y 25 positivos bien detectados a 17 y 28, respectivamente, ganando en total un 8% de precisión.El modelo es aceptable, la sensibilidad del modelo es del 84%, lo cual es bastante bueno ya que el factor crítico aquí es detectar los positivos, los falsos positivos no tienen tanta criticidad.

Por último se va a predecir todo el modelo para observar el resultado.
```{r}
sum(tab[,2])
```

```{r}
predictions = predict(lr_model1, df_heart)
tab = table(predictions>0.5, df_heart$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)

predictions = predict(lr_model2, df_heart)
tab = table(predictions>0.5, df_heart$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)

```

Habiendo predicho todo el dataset podemos ver que la mejoría en el segundo modelo se reduce, aunque sigue estando presente.
Al ser un modelo lineal vemos que además la presencia de sobrentrenamiento es nula, de hecho los resultados han empeorado al incluir todo el dataset.

La precisión en este caso es del 73% y la sensibilidad del 82%.

Ahora vamos a probar con un modelo lógico, entrenándolo con las variables categóricas. 

```{r}
logic_model = glm(formula=output~slp+thall+caa+exng+restecg+sex+cp+fbs, data=train_df, family=binomial)
summary(logic_model)
```
Vemos que el nivel de significancia de restecg y el de fbs son muy bajos, su valor p no está por debajo de 0.05. Vamos a representar también la criticidad de cada una de las variables ante la presencia de positivos.

```{r}
exp(coefficients(logic_model))
```
Vemos que **slp**, **cp** y **fbs** son mayores que uno, lo que quiere decir que la influencia de estas variables es alta en la presencia de 1 como output.


```{r}
logic_model2 = glm(formula=output~slp+thall+caa+exng+sex+cp, data=train_df, family=binomial)
```

```{r}
predictions = predict(logic_model, test_df)
tab = table(predictions>0.5, test_df$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)


predictions = predict(logic_model2, test_df)
tab = table(predictions>0.5, test_df$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)

```
Vemos que los resultados son muy similares al modelo anterior, sin embargo la eliminación de variables que habíamos detectado que tenían un bajo valor de significancia en este caso empeoran sutilmente el resultado, repercutiendo con una pérdida de un casi 2% de precisión y 3% de sensibilidad.

Se presentan de nuevo los resultados para todo el dataset.

```{r}
predictions = predict(logic_model, df_heart)
tab = table(predictions>0.5, df_heart$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)


predictions = predict(logic_model2, df_heart)
tab = table(predictions>0.5, df_heart$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)

```
El resultado para todo el dataset si que es mejor que del del modelo lineal y se dispersa un poco las pérdidas del modelo ajustado con menos variables. Vamos a añadir las dos variables discretas con las que hemos ajustado el modelo **lm** y observar si obtenemos una mejora en las predicciones.

```{r}
logic_model3 = glm(formula=output~slp+thall+caa+exng+restecg+sex+cp+fbs+thalachh+oldpeak, data=train_df, family=binomial)

predictions = predict(logic_model3, test_df)
tab = table(predictions>0.5, test_df$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)


predictions = predict(logic_model3, df_heart)
tab = table(predictions>0.5, df_heart$output)
tab
acc = sum(diag(tab)) / sum(tab)
sprintf("Precisión: %s", acc)
sens = tab[2,2] / sum(tab[,2])
sprintf("Sensibilidad:%s", sens)
```
Vemos que para el set de test no existe mejora, a pesar de que si la hay si utilizamos el conjunto entero, no podemos asegurar que el modelo sea mejor.

